# Describe and document your code here
Last week we've met with Lea, we were discussing the workflow pipeline and how it should be working.
We've been also experimenting with Google Colab and Jupyter Notebook, we've met these things for the first time.

I've chosen some LLMs that i'd love to test:
Phi-3 (2,7B-3,8B) - it is a great choice for weaker hardware, works fine on CPU with only 4GB of RAM.
Gemma-3 (4B) - has 128K context window, is multimodal and also works fine on CPU, which is great since i don't have high-end GPU.
Mistral (7B) - very popular small model in homelabbing community
Mistral Nemo (12B) - more complex model, i'll see what i'll be able to do with this. 


We were also trying to incorporate the NTUMC tagger, but we did not really understand it. 
